{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61246316-d2c1-4bd8-abbb-d6d7d15850a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54160561-9464-4f8b-94c8-f24297fce4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a7c1d90-996a-4e17-99a2-1ae1aa0c3449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal länkar hittade: 40\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Kör utan GUI\n",
    "options = Options()\n",
    "#options.add_argument(\"--headless\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\")\n",
    "\n",
    "\n",
    "# Initialization of variables\n",
    "base_url = \"https://www.blocket.se\"\n",
    "pagination_url = \"https://www.blocket.se/bilar/sok?filter=%7B%22key%22%3A%22price%22%2C%22range%22%3A%7B%22start%22%3A%2220000%22%2C%22end%22%3A%22%22%7D%7D&filter=%7B%22key%22%3A%22modelYear%22%2C%22range%22%3A%7B%22start%22%3A%222005%22%2C%22end%22%3A%22%22%7D%7D&filter=%7B%22key%22%3A%22ownershipType%22%2C%22values%22%3A%5B%22K%C3%B6pa%22%5D%7D&filter=%7B%22key%22%3A%22fuel%22%2C%22values%22%3A%5B%22El%22%5D%7D&q=EJ+a-traktor&page=\"\n",
    "total_no_of_pages = 1 # Verkligt antal sidor\n",
    "# total_no_of_pages = 2 # För test\n",
    "\n",
    "link_list = []\n",
    "\n",
    "# Start Chrome WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Function to get BeautifulSoup DOM from a given URL\n",
    "def get_dom(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Wait for JS to load\n",
    "    page_content = driver.page_source\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "# Loop through pages and collect URLs\n",
    "for page_no in range(1, total_no_of_pages + 1):\n",
    "    page_url = pagination_url + str(page_no)\n",
    "    soup = get_dom(page_url)\n",
    "    \n",
    "    # Find the main container with class=\"list w-full\"\n",
    "    container = soup.find(\"div\", class_=\"list w-full\")\n",
    "    \n",
    "    if container:\n",
    "        links = container.find_all(\"a\", href=True)\n",
    "        for a in links:\n",
    "            full_url = a[\"href\"]\n",
    "            if not full_url.startswith(\"http\"):\n",
    "                full_url = base_url + full_url\n",
    "            link_list.append(full_url)\n",
    "\n",
    "# Output result\n",
    "print(\"Antal länkar hittade:\", len(link_list))\n",
    "#for link in link_list:\n",
    "#    print(link)\n",
    "with open('lankar.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['URL'])  # Rubrikrad\n",
    "    for link in link_list:\n",
    "        csv_writer.writerow([link])\n",
    "\n",
    "# Stäng WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bf9a0f9-e33a-4be5-8edc-1b9f4dd824b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "resultat_lista = []\n",
    "link_list2 = [\"https://www.blocket.se/annons/1002069529\"]\n",
    "\n",
    "for link in link_list2:\n",
    "    try:\n",
    "        response = requests.get(link, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            element = soup.find(id=\"skip-tabbar\")\n",
    "\n",
    "            if element:\n",
    "                text = element.get_text()\n",
    "                match = re.search(r\"eMJjcF(\\w+)\", text)\n",
    "                if match:\n",
    "                    resultat = match.group(1)\n",
    "                    resultat_lista.append((link, resultat))\n",
    "                else:\n",
    "                    resultat_lista.append((link, \"Ingen match\"))\n",
    "            else:\n",
    "                resultat_lista.append((link, \"Element saknas\"))\n",
    "        else:\n",
    "            resultat_lista.append((link, f\"Felkod {response.status_code}\"))\n",
    "\n",
    "        # Vänta lite mellan förfrågningar\n",
    "        time.sleep(1 + random.uniform(0, 1.5))\n",
    "\n",
    "    except Exception as e:\n",
    "        resultat_lista.append((link, f\"Fel: {str(e)}\"))\n",
    "\n",
    "# Spara till CSV\n",
    "with open('resultat.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow(['Länk', 'Matchad sträng'])\n",
    "    for row in resultat_lista:\n",
    "        csv_writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77e80421-6b4e-4a97-8697-7ce3593f2d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://www.blocket.se/annons/1002069529', 'Blocket är en del av Schibsted Marketplaces.')]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "resultat_lista = []\n",
    "\n",
    "for link in link_list2:\n",
    "    try:\n",
    "        response = requests.get(link, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "\n",
    "            # Hitta alla förekomster av \"</div>\" och extrahera texten innan\n",
    "            matches = re.findall(r'>([^<]+)</div>', html)\n",
    "\n",
    "            if matches:\n",
    "                for match in matches:\n",
    "                    resultat_lista.append((link, match.strip()))\n",
    "            else:\n",
    "                resultat_lista.append((link, \"Ingen match\"))\n",
    "\n",
    "        else:\n",
    "            resultat_lista.append((link, f\"Felkod {response.status_code}\"))\n",
    "\n",
    "        # Vänta lite mellan förfrågningar\n",
    "        time.sleep(1 + random.uniform(0, 1.5))\n",
    "\n",
    "    except Exception as e:\n",
    "        resultat_lista.append((link, f\"Fel: {str(e)}\"))\n",
    "\n",
    "# Spara resultat till CSV\n",
    "with open('div_innehall.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow(['Länk', 'Innehåll före </div>'])\n",
    "\n",
    "    for row in resultat_lista:\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "print(resultat_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc7898f-edf9-45ce-b548-b7fa370bfc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ce8c0f8-8e32-457c-b9e5-7ac56ecfa34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://www.blocket.se/annons/1002069529', 'Ingen match')]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "resultat_lista = []\n",
    "\n",
    "for link in link_list2:\n",
    "    try:\n",
    "        response = requests.get(link, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Hämta alla <div> där någon av klasserna är 'eMJjcF'\n",
    "            #divs = soup.find_all(\"div\", class_=\"eMJjcF\")\n",
    "            divs = soup.find_all(\"div\", class_=lambda x: x and \"eMJjcF\" in x)\n",
    "\n",
    "\n",
    "            if divs:\n",
    "                for div in divs:\n",
    "                    text = div.get_text(strip=True)\n",
    "                    resultat_lista.append((link, text))\n",
    "            else:\n",
    "                resultat_lista.append((link, \"Ingen match\"))\n",
    "\n",
    "        else:\n",
    "            resultat_lista.append((link, f\"Felkod {response.status_code}\"))\n",
    "\n",
    "        time.sleep(1 + random.uniform(0, 1.5))\n",
    "\n",
    "    except Exception as e:\n",
    "        resultat_lista.append((link, f\"Fel: {str(e)}\"))\n",
    "\n",
    "# Spara till CSV\n",
    "with open('matchade_divar.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow(['Länk', 'Text i <div class=\"eMJjcF\">'])\n",
    "    for row in resultat_lista:\n",
    "        csv_writer.writerow(row)\n",
    "        \n",
    "print(resultat_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf494520-1ff2-43f1-b403-2b18b44c8e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1620d5be-b8fa-4122-abc1-34e3c89623ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f8d62-8a39-4f06-804a-08e233938d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9820f-d018-4f3f-a753-9cde7720b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "resultat_lista = []\n",
    "\n",
    "for link in link_list:\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        time.sleep(5)  # Vänta på att sidan ska ladda\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        element = soup.find(id=\"skip-tabbar\")\n",
    "\n",
    "        if element:\n",
    "            text = element.get_text()\n",
    "            match = re.search(r\"eMJjcF(\\w+)\", text)\n",
    "            if match:\n",
    "                resultat = match.group(1)\n",
    "                resultat_lista.append((link, resultat))\n",
    "            else:\n",
    "                resultat_lista.append((link, \"Ingen match\"))\n",
    "        else:\n",
    "            resultat_lista.append((link, \"Element saknas\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        resultat_lista.append((link, f\"Fel: {str(e)}\"))\n",
    "\n",
    "# Spara i CSV\n",
    "with open('resultat.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow(['Länk', 'Matchad sträng'])\n",
    "    for row in resultat_lista:\n",
    "        csv_writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
